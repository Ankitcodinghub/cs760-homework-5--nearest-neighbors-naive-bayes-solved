# cs760-homework-5--nearest-neighbors-naive-bayes-solved
**TO GET THIS SOLUTION VISIT:** [CS760 Homework 5- Nearest Neighbors & Naive Bayes Solved](https://www.ankitcodinghub.com/product/cs760-homework-5-nearest-neighbors-naive-bayes-solved/)


---

ðŸ“© **If you need this solution or have special requests:** **Email:** ankitcoding@gmail.com  
ðŸ“± **WhatsApp:** +1 419 877 7882  
ðŸ“„ **Get a quote instantly using this form:** [Ask Homework Questions](https://www.ankitcodinghub.com/services/ask-homework-questions/)

*We deliver fast, professional, and affordable academic help.*

---

<h2>Description</h2>



<div class="kk-star-ratings kksr-auto kksr-align-center kksr-valign-top" data-payload="{&quot;align&quot;:&quot;center&quot;,&quot;id&quot;:&quot;117460&quot;,&quot;slug&quot;:&quot;default&quot;,&quot;valign&quot;:&quot;top&quot;,&quot;ignore&quot;:&quot;&quot;,&quot;reference&quot;:&quot;auto&quot;,&quot;class&quot;:&quot;&quot;,&quot;count&quot;:&quot;2&quot;,&quot;legendonly&quot;:&quot;&quot;,&quot;readonly&quot;:&quot;&quot;,&quot;score&quot;:&quot;5&quot;,&quot;starsonly&quot;:&quot;&quot;,&quot;best&quot;:&quot;5&quot;,&quot;gap&quot;:&quot;4&quot;,&quot;greet&quot;:&quot;Rate this product&quot;,&quot;legend&quot;:&quot;5\/5 - (2 votes)&quot;,&quot;size&quot;:&quot;24&quot;,&quot;title&quot;:&quot;CS760 Homework 5- Nearest Neighbors \u0026amp; Naive Bayes Solved&quot;,&quot;width&quot;:&quot;138&quot;,&quot;_legend&quot;:&quot;{score}\/{best} - ({count} {votes})&quot;,&quot;font_factor&quot;:&quot;1.25&quot;}">

<div class="kksr-stars">

<div class="kksr-stars-inactive">
            <div class="kksr-star" data-star="1" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" data-star="2" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" data-star="3" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" data-star="4" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" data-star="5" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
    </div>

<div class="kksr-stars-active" style="width: 138px;">
            <div class="kksr-star" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
    </div>
</div>


<div class="kksr-legend" style="font-size: 19.2px;">
            5/5 - (2 votes)    </div>
    </div>
In this homework you will use nearest neighbors and naive bayes to determine whether you would have survived the Titanic sinking, and compare your results to those obtained with previous algorithms. To find out, we will use the titanic dataset (titanic_data.csv), containing the following information about 887 passengers: 1) whether they survived or not (1 = survived, 0 = deceased), 2) passenger class, 3) gender (0 = male, 1 = female), 4) age, 5) number of siblings/spouses aboard, 6) number of parents/children aboard, and 7) fare:

Passenger 1 Passenger 2 Passenger 3 Â·Â·Â· Passenger 887

Survived 0 1 1 Â·Â·Â· 0

Passenger Class 3 1 3 Â·Â·Â· 3

Gender 0 1 1 Â·Â·Â· 0

Age 22 38 26 Â·Â·Â· 32

Siblings/Spouses 1 1 0 Â·Â·Â· 0

Parents/Children 0 0 0 Â·Â·Â· 0

Fare 7.25 71.2833 7.925 Â·Â·Â· 7.75

Each subproblem is worth 10 points.

Problem 5.1. Nearest Neighbors

(a) Write your own code to implement your favorite variant of K-nearest neighbors that seems appropriate to predict whether you would have survived the titanic sinking or not. Explain your choice/reasoning, and submit your code in an appendix.

(b) What measure of distance did you use, and why do you think this is this a good idea?

(c) Build your own feature vector x. For K = 1,2,â€¦,N, would you have survived the titanic sinking? Describe your results with a plot.

(d) In light of this, what do you think would be the best choice of K, and why?

(e) Describe how you could assess the reliability (confidence) of your results?

Problem 5.2. Naive Bayes

(a) Write your own code to implement Naive Bayes. Submit your code in an appendix.

(b) How did you model each variable (e.g., Bernoulli, Multinomial, Gaussian), and why?

(c) Build your own feature vector x. According to your Naive Bayes classifier, would you have survived the titanic sinking?

(d) Describe how you could assess the reliability (confidence) of your results?

Problem 5.3. Out of all the methods that you have used so far for this dataset, which would you prefer, and why?

5-1
